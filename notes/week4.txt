Week 4
---------------------------------------
VIII. Neural Networks: Representation
---------------------------------------
Neural Networks:
----------------
activation function -> g(z)
weights -> parameters
input layer(x1, x2, x3) -> hidden layer(a1, a2, a3) -> output layer(h(x))
a_i_j = "activation" of unit i in layer j
theta__j = matrix of weights controlling function mapping from layer j to layer j + 1
a_1_2 = g(theta_10_1＊x_0 ＋ theta_11_1＊x_1 ＋ theta_12_1＊x_2 ＋ theta_13_1＊x_3)
a_2_2 = g(theta_20_1＊x_0 ＋ theta_21_1＊x_1 ＋ theta_22_1＊x_2 ＋ theta_23_1＊x_3)
a_3_2 = g(theta_30_1＊x_0 ＋ theta_31_1＊x_1 ＋ theta_32_1＊x_2 ＋ theta_33_1＊x_3)
h(x) = a_1_3 = g(theta_10_2*a_0_2 + theta_11_2*a_1_2 + theta_12_2*a_2_2 + theta_13_2*a_3_2)
theta__1 -> matrix 3x4
If network has s_j units in layer j, s_j+1 units in layer j+1, then theta__j will
be of dimension s_j+1 x (s_j + 1)
